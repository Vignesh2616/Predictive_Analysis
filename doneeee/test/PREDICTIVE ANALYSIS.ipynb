{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d93608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import log\n",
    "from pyspark.sql.functions import lag\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark=SparkSession.builder.appName('price_model').getOrCreate()\n",
    "\n",
    "dataframe = spark.read.csv(\"/Internship/solar_Data_View/solar_Data/Solar_typical_src.csv\" , inferSchema = True , header = True)\n",
    "\n",
    "df=dataframe.select('VPJ_Job_Code', 'Job' ,'VPJ_Valuation_Year','VPJ_Org_contract_value','VPJ_Valuation_Month' ,'VPJ_Rev_contract_value', 'VPJ_Invoice_certified',\\\n",
    "'VPJ_Contingency_calculated','VPJ_wip_cost','VPJ_Expected_End_Date','VPJ_wip_rsv','VPJ_Expected_certified','VPJ_rev_cost','VPJ_CostCompPC','VPJ_Cum_Cost_AC','VPJ_Contract_Start_Date')\\\n",
    ".where(\"(VPJ_Rev_contract_value-VPJ_Invoice_certified!=0 or VPJ_Rev_contract_value-VPJ_Expected_certified!=0) and VPJ_rev_cost!=0  and VPJ_Job_Code in('J384','G755','J353','J082','H653','K081') \")\n",
    "\n",
    "df1=dataframe.select('VPJ_Job_Code', 'Job' ,'VPJ_Valuation_Year', 'VPJ_Org_contract_value' ,'VPJ_Valuation_Month' ,'VPJ_Rev_contract_value', 'VPJ_Invoice_certified',\\\n",
    "'VPJ_Contingency_calculated','VPJ_wip_cost','VPJ_Expected_End_Date','VPJ_wip_rsv','VPJ_Expected_certified','VPJ_rev_cost','VPJ_CostCompPC','VPJ_Cum_Cost_AC','VPJ_Contract_Start_Date')\\\n",
    ".where(\"(VPJ_Rev_contract_value-VPJ_Invoice_certified=0 or VPJ_Rev_contract_value-VPJ_Expected_certified=0) and VPJ_Job_Code in('J384','G755','J353','J082','H653','K081')  \")\n",
    "\n",
    "windowSpec=Window.partitionBy('VPJ_Job_Code','Job','VPJ_Rev_contract_value','VPJ_Invoice_certified',\\\n",
    "'VPJ_Contingency_calculated','VPJ_wip_cost','VPJ_wip_rsv','VPJ_rev_cost','VPJ_CostCompPC','VPJ_Cum_Cost_AC','VPJ_Contract_Start_Date').orderBy('VPJ_Valuation_Year','VPJ_Valuation_Month')\n",
    "\n",
    "df_row=df1.withColumn(\"row_number\",row_number().over(windowSpec))\n",
    "df_test=df_row.select(\"*\").where(\"row_number='1'\")\n",
    "df_test=df_test.drop(\"row_number\")\n",
    "\n",
    "df3=df.union(df_test)\n",
    "\n",
    "windowSpec=Window.partitionBy('VPJ_Job_Code').orderBy('VPJ_Valuation_Year','VPJ_Valuation_Month')\n",
    "df4 = df3.withColumn(\"Month\",row_number().over(windowSpec))\n",
    "\n",
    "#df6 = df4.select([max(\"Month\")])\n",
    "\n",
    "#df_collect=df6.collect()[0][0]\n",
    "\n",
    "df6 = df4.select(\"*\").groupby('VPJ_Job_Code').agg(max('Month').alias(\"Month_max\"))\n",
    "df6.createOrReplaceTempView(\"df6\")\n",
    "\n",
    "df_6=spark.sql(\"Select VPJ_Job_Code as Job_Code , Month_max from df6\")\n",
    "\n",
    "df_collect=df4.join(df_6,df4.VPJ_Job_Code==df_6.Job_Code,\"left\")\n",
    "\n",
    "df5 = df_collect.withColumn(\"POT\", ((df_collect[\"Month\"]/df_collect['Month_max'])*100))  \n",
    "\n",
    "df7 = df5.withColumn(\"sales\" , df5['VPJ_wip_cost'] + df5['VPJ_wip_rsv']).withColumn(\"CC\" , (df5[\"VPJ_Cum_Cost_AC\"]/(df5['VPJ_rev_cost']+ df5['VPJ_Contingency_calculated']))*100)\n",
    "\n",
    "df9 = df7.withColumn(\"logval\" , log('sales'))\n",
    "\n",
    "df10 = df9.withColumn(\"VPJ_Cost_M\" , col('VPJ_Cum_Cost_AC') - lag(col('VPJ_Cum_Cost_AC'), 1,0).over(windowSpec))\n",
    "#df5.repartition(1).write.format('csv').mode('overwrite').save(\"/Internship/8922_HYD/\",header=True)\n",
    "\n",
    "df11 = df10.withColumn(\"SOI\" , df10[\"sales\"] - df10[\"VPJ_Expected_certified\"])\n",
    "\n",
    "df12 = df11.withColumn(\"SP\" ,(df11[\"sales\"] / df11[\"VPJ_Org_contract_value\"])*100)\n",
    "\n",
    "df13 = df12.where('CC >= 25')\n",
    "\n",
    "df14 = df12.withColumn(\"CP\" , (df13[\"VPJ_Cum_Cost_AC\"] / df13[\"VPJ_Org_contract_value\"])*100 ).select('VPJ_Job_Code','VPJ_Cost_M','CC','POT','SOI','VPJ_Cum_Cost_AC','SP','CP')\n",
    "\n",
    "df14.repartition(1).write.format('csv').mode('overwrite').save(\"/Internship/Test/Mod1\",header=True)\n",
    "\n",
    "op:FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "\n",
    "\n",
    "\n",
    "df14.show(5)\n",
    "op:\n",
    "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "+------------+----------+-------------------+----+------------+---------------+------------------+------------------+\n",
    "|VPJ_Job_Code|VPJ_Cost_M|                 CC| POT|         SOI|VPJ_Cum_Cost_AC|                SP|                CP|\n",
    "+------------+----------+-------------------+----+------------+---------------+------------------+------------------+\n",
    "|        J384|         0|                0.0| 2.5|         0.0|              0|               0.0|               0.0|\n",
    "|        J384|   2631202|0.28876233109667626| 5.0|   2631203.0|        2631202| 0.268549069935981|0.2685489678727537|\n",
    "|        J384|   9922247|  1.377683354050065| 7.5|  1.255345E7|       12553449|1.2812456211048107| 1.281245519041583|\n",
    "|        J384|  31607735|  5.383929778184517|10.0|-5.9971166E7|       44161184| 4.501891482677934| 4.507232961680161|\n",
    "|        J384|  49663669| 11.438697386385403|12.5|-8.7009523E7|       93824853| 9.570725719720587| 9.576067300786043|\n",
    "+------------+----------+-------------------+----+------------+---------------+------------------+------------------+\n",
    "only showing top 5 rows\n",
    "\n",
    "\n",
    "\n",
    "#import six\n",
    "#for i in df14.columns:\n",
    "   # if not (isinstance(df14.select(i).take(1)[0][0],six.string_types)):\n",
    "      #  print(\"Correlation to SP for \" ,i,df14.stat.corr('SP', i))\n",
    "op:FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_fin = df14.select('SP','POT' ,'CC','CP').where('SP !=0')\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "df8 = df_fin.drop('SP')\n",
    "assembler = VectorAssembler(inputCols = df8.columns, outputCol = 'features')\n",
    "output=assembler.transform(df_fin)\n",
    "#vector_col=output.select('features')\n",
    "\n",
    "print(df_fin.count())\n",
    "df8.show(10)\n",
    "print(assembler)\n",
    "op:\n",
    "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "278\n",
    "+------------------+-------------------+------------------+\n",
    "|               POT|                 CC|                CP|\n",
    "+------------------+-------------------+------------------+\n",
    "|               5.0|0.28876233109667626|0.2685489678727537|\n",
    "|               7.5|  1.377683354050065| 1.281245519041583|\n",
    "|              10.0|  5.383929778184517| 4.507232961680161|\n",
    "|              12.5| 11.438697386385403| 9.576067300786043|\n",
    "|              15.0|  57.60810346560847| 47.40446568587961|\n",
    "|              17.5|   64.1266636654239|54.618309902929994|\n",
    "|              20.0|  82.03090822286975| 69.86781021871974|\n",
    "|              22.5|  87.26379054432446| 76.81706817476163|\n",
    "|              25.0|  86.99616418879977| 76.58148052615455|\n",
    "|27.500000000000004|  94.97353697436898|  77.1953854291834|\n",
    "+------------------+-------------------+------------------+\n",
    "only showing top 10 rows\n",
    "\n",
    "VectorAssembler_e5e314f4651b\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "vector_col=output.select('features')\n",
    "matrix=Correlation.corr(vector_col,'features')\n",
    "dfm=matrix.collect()[0][matrix.columns[0]].toArray()\n",
    "\n",
    "#output.show()\n",
    "dfm = dfm.tolist()\n",
    "\n",
    "mat = spark.createDataFrame(dfm , df8.columns)\n",
    "\n",
    "namecol = mat.columns\n",
    "\n",
    "pd_df=mat.toPandas()\n",
    "pd_df['Names']=namecol\n",
    "\n",
    "mat_new=spark.createDataFrame(pd_df)\n",
    "\n",
    "mat_new_s=mat_new.select('Names','POT')\n",
    "mat_new_s.show()\n",
    "op:\n",
    "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "+-----+------------------+\n",
    "|Names|               POT|\n",
    "+-----+------------------+\n",
    "|  POT|               1.0|\n",
    "|   CC|0.6834024523032113|\n",
    "|   CP|0.2298785950292954|\n",
    "+-----+------------------+\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_reg = output.select(['features' , 'SP'])\n",
    "df_reg.show(5)\n",
    "\n",
    "#print(train_df)\n",
    "#test_df.show(5)\n",
    "#print(test_df.count())\n",
    "#print(train_df.count())\n",
    "#print(df_reg.count())\n",
    "op:\n",
    "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "+--------------------+------------------+\n",
    "|            features|                SP|\n",
    "+--------------------+------------------+\n",
    "|[5.0,0.2887623310...| 0.268549069935981|\n",
    "|[7.5,1.3776833540...|1.2812456211048107|\n",
    "|[10.0,5.383929778...| 4.501891482677934|\n",
    "|[12.5,11.43869738...| 9.570725719720587|\n",
    "|[15.0,57.60810346...| 54.86510603309903|\n",
    "+--------------------+------------------+\n",
    "only showing top 5 rows\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol = \"features\", labelCol = \"SP\" , maxIter = 10 , regParam = 0.3 , elasticNetParam = 0.8)\n",
    "\n",
    "lr_model = lr.fit(df_reg)\n",
    "\n",
    "print(\"Coefficients\" + str(lr_model.coefficients))\n",
    "print(\"Intercept\" + str(lr_model.intercept))\n",
    "op:FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "Coefficients[-0.022967812349807208,0.06503171993188835,1.0177132661655584]\n",
    "Intercept0.33423092432761825\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE : %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2 : %f\" % trainingSummary.r2)\n",
    "op:FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "RMSE : 6.340395\n",
    "r2 : 0.980350\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tdf= dataframe.select('VPJ_Job_Code', 'Job' ,'VPJ_Valuation_Year' ,'VPJ_Org_contract_value' ,'VPJ_Valuation_Month' ,'VPJ_Rev_contract_value', 'VPJ_Invoice_certified',\\\n",
    "'VPJ_Contingency_calculated','VPJ_wip_cost','VPJ_wip_rsv','VPJ_Expected_certified','VPJ_Expected_End_Date','VPJ_Expected_Completion_Date','VPJ_rev_cost','VPJ_CostCompPC','VPJ_Cum_Cost_AC','VPJ_Contract_Start_Date')\\\n",
    ".where(\"VPJ_Rev_contract_value-VPJ_Invoice_certified!=0 and VPJ_Job_Code= 'J384' and VPJ_rev_cost!=0  \")\n",
    "\n",
    "print(tdf.count())\n",
    "\n",
    "tdf1= dataframe.select('VPJ_Job_Code', 'Job' ,'VPJ_Valuation_Year' ,'VPJ_Org_contract_value' ,'VPJ_Valuation_Month' ,'VPJ_Rev_contract_value', 'VPJ_Invoice_certified',\\\n",
    "'VPJ_Contingency_calculated','VPJ_wip_cost','VPJ_wip_rsv','VPJ_Expected_certified','VPJ_Expected_End_Date','VPJ_Expected_Completion_Date','VPJ_rev_cost','VPJ_CostCompPC','VPJ_Cum_Cost_AC','VPJ_Contract_Start_Date')\\\n",
    ".where(\"VPJ_Rev_contract_value-VPJ_Invoice_certified=0 and VPJ_Job_Code= 'J384' and VPJ_rev_cost!=0 \")\n",
    "\n",
    "print(tdf1.count())\n",
    "\n",
    "windowSpec=Window.partitionBy('VPJ_Job_Code','Job','VPJ_Rev_contract_value','VPJ_Invoice_certified',\\\n",
    "'VPJ_Contingency_calculated','VPJ_wip_cost','VPJ_wip_rsv','VPJ_rev_cost','VPJ_CostCompPC','VPJ_Cum_Cost_AC','VPJ_Contract_Start_Date').orderBy('VPJ_Valuation_Year','VPJ_Valuation_Month')\n",
    "\n",
    "tdf_row=tdf1.withColumn(\"row_number\",row_number().over(windowSpec))\n",
    "tdf_test=tdf_row.select(\"*\").where(\"row_number='1'\")\n",
    "tdf_test=tdf_test.drop(\"row_number\")\n",
    "\n",
    "tdf3=tdf.union(tdf_test)\n",
    "\n",
    "windowSpec=Window.partitionBy('VPJ_Job_Code').orderBy('VPJ_Valuation_Year','VPJ_Valuation_Month')\n",
    "tdf4 = tdf3.withColumn(\"Month\",row_number().over(windowSpec))\n",
    "\n",
    "tdf6 = tdf4.select(\"*\").groupby('VPJ_Job_Code').agg(max('Month').alias(\"Month_max\"))\n",
    "tdf6.createOrReplaceTempView(\"tdf6\")\n",
    "\n",
    "tdf_6=spark.sql(\"Select VPJ_Job_Code as Job_Code , Month_max from tdf6\")\n",
    "\n",
    "tdf_collect=tdf4.join(tdf_6,tdf4.VPJ_Job_Code==tdf_6.Job_Code,\"left\")\n",
    "\n",
    "'''\n",
    "tdf6 = tdf4.select([max(\"Month\")])\n",
    "\n",
    "tdf_collect=tdf6.collect()[0][0]\n",
    "'''\n",
    "tdf_collect = tdf_collect.withColumn(\"POT\", (tdf_collect[\"Month\"]/tdf_collect['Month_max'])*100)\n",
    "\n",
    "#tdf5 = tdf4.withColumn(\"POT\", (tdf4[\"Month\"]/tdf_collect)*100)\n",
    "\n",
    "tdf7 = tdf_collect.withColumn(\"sales\" , tdf_collect['VPJ_wip_cost'] + tdf_collect['VPJ_wip_rsv']).withColumn(\"CC\" , (tdf_collect[\"VPJ_Cum_Cost_AC\"]/(tdf_collect['VPJ_rev_cost']+ tdf_collect['VPJ_Contingency_calculated']))*100)\n",
    "\n",
    "tdf9 = tdf7.withColumn(\"logval\" , log('sales'))\n",
    "\n",
    "tdf9.show(5)\n",
    "\n",
    "\n",
    "tdf10 = tdf9.withColumn(\"VPJ_Cost_M\" , col('VPJ_Cum_Cost_AC') - lag(col('VPJ_Cum_Cost_AC'), 1,0).over(windowSpec))\n",
    "\n",
    "tdf11 = tdf10.withColumn(\"SOI\" , tdf10[\"sales\"] - tdf10[\"VPJ_Expected_certified\"])\n",
    "\n",
    "tdf12 = tdf11.withColumn(\"SP\" ,(tdf11[\"sales\"] / tdf11[\"VPJ_Org_contract_value\"])*100)\n",
    "\n",
    "tdf13 = tdf12.where('CC >= 25')\n",
    "\n",
    "tdf14 = tdf12.withColumn(\"CP\" , (tdf13[\"VPJ_Cum_Cost_AC\"] / tdf13[\"VPJ_Org_contract_value\"])*100 ).select('SP','POT' ,'CC','CP')\n",
    "\n",
    "tdf14.repartition(1).write.format('csv').mode('overwrite').save(\"/Internship/Test/Mod2\",header=True)\n",
    "op:\n",
    "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "38\n",
    "2\n",
    "+------------+----------+------------------+----------------------+-------------------+----------------------+---------------------+--------------------------+------------+-----------+----------------------+---------------------+----------------------------+-------------+--------------+---------------+-----------------------+-----+--------+---------+----+--------+-------------------+------------------+\n",
    "|VPJ_Job_Code|       Job|VPJ_Valuation_Year|VPJ_Org_contract_value|VPJ_Valuation_Month|VPJ_Rev_contract_value|VPJ_Invoice_certified|VPJ_Contingency_calculated|VPJ_wip_cost|VPJ_wip_rsv|VPJ_Expected_certified|VPJ_Expected_End_Date|VPJ_Expected_Completion_Date| VPJ_rev_cost|VPJ_CostCompPC|VPJ_Cum_Cost_AC|VPJ_Contract_Start_Date|Month|Job_Code|Month_max| POT|   sales|                 CC|            logval|\n",
    "+------------+----------+------------------+----------------------+-------------------+----------------------+---------------------+--------------------------+------------+-----------+----------------------+---------------------+----------------------------+-------------+--------------+---------------+-----------------------+-----+--------+---------+----+--------+-------------------+------------------+\n",
    "|        J384|Tamil Nadu|              2019|          9.79784812E8|                  3|          9.79784812E8|                  0.0|               2.9393544E7|           0|          0|                   0.0|           14-11-2019|                  14-11-2019|8.818063308E8|           0.0|              0|             06-02-2019|    1|    J384|       40| 2.5|       0|                0.0|              null|\n",
    "|        J384|Tamil Nadu|              2019|          9.79784812E8|                  4|          9.79784812E8|                  0.0|               2.9393544E7|     2631203|          0|                   0.0|           14-11-2019|                  14-11-2019| 8.81806331E8|          0.29|        2631202|             06-02-2019|    2|    J384|       40| 5.0| 2631203|0.28876233109667626|14.782951714020518|\n",
    "|        J384|Tamil Nadu|              2019|          9.79784812E8|                  5|          9.79784812E8|                  0.0|               2.9393544E7|    12553450|          0|                   0.0|           14-11-2019|                  14-11-2019| 8.81806331E8|          1.38|       12553449|             06-02-2019|    3|    J384|       40| 7.5|12553450|  1.377683354050065| 16.34550608616228|\n",
    "|        J384|Tamil Nadu|              2019|          9.79784812E8|                  6|          9.79784812E8|          5.9080015E7|               2.7993852E7|    44108849|          0|          1.04080015E8|           14-11-2019|                  14-11-2019| 7.92246861E8|          5.38|       44161184|             06-02-2019|    4|    J384|       40|10.0|44108849|  5.383929778184517|17.602170977884402|\n",
    "|        J384|Tamil Nadu|              2019|          9.79784812E8|                  7|          9.79784812E8|          1.3578204E8|               2.7993852E7|    93772517|          0|           1.8078204E8|           14-11-2019|                  14-11-2019| 7.92246861E8|         11.44|       93824853|             06-02-2019|    5|    J384|       40|12.5|93772517| 11.438697386385403| 18.35638237530921|\n",
    "+------------+----------+------------------+----------------------+-------------------+----------------------+---------------------+--------------------------+------------+-----------+----------------------+---------------------+----------------------------+-------------+--------------+---------------+-----------------------+-----+--------+---------+----+--------+-------------------+------------------+\n",
    "only showing top 5 rows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tdf=dataframe.select('VPJ_Job_Code', 'Job' ,'VPJ_Valuation_Year' ,'VPJ_Org_contract_value' ,'VPJ_Valuation_Month' ,'VPJ_Rev_contract_value', 'VPJ_Invoice_certified',\\\n",
    "'VPJ_Contingency_calculated','VPJ_wip_cost','VPJ_wip_rsv','VPJ_Expected_certified','VPJ_rev_cost','VPJ_CostCompPC','VPJ_Cum_Cost_AC','VPJ_Contract_Start_Date')\\\n",
    ".where(\"VPJ_Rev_contract_value-VPJ_Invoice_certified!=0 and VPJ_Job_Code='8939' and VPJ_rev_cost!=0 and VPJ_Rev_contract_value!=-0  and VPJ_Job_Code in('J384','G755','J353','J082','H653','K081') \")\n",
    "\n",
    "print(tdf.count())\n",
    "\n",
    "tdf1=dataframe.select('VPJ_Job_Code', 'Job' ,'VPJ_Valuation_Year','VPJ_Expected_certified','VPJ_Org_contract_value' ,'VPJ_Valuation_Month' ,'VPJ_Rev_contract_value', 'VPJ_Invoice_certified',\\\n",
    "'VPJ_Contingency_calculated','VPJ_wip_cost','VPJ_wip_rsv','VPJ_rev_cost','VPJ_CostCompPC','VPJ_Cum_Cost_AC','VPJ_Contract_Start_Date')\\\n",
    ".where(\"VPJ_Rev_contract_value-VPJ_Invoice_certified=0 and VPJ_Job_Code='8939' and VPJ_Rev_contract_value!=0  and VPJ_Job_Code in('J384','G755','J353','J082','H653','K081') \")\n",
    "print(tdf1.count())\n",
    "\n",
    "windowSpec=Window.partitionBy('VPJ_Job_Code','Job','VPJ_Rev_contract_value','VPJ_Invoice_certified',\\\n",
    "'VPJ_Contingency_calculated','VPJ_wip_cost','VPJ_wip_rsv','VPJ_rev_cost','VPJ_CostCompPC','VPJ_Cum_Cost_AC','VPJ_Contract_Start_Date').orderBy('VPJ_Valuation_Year','VPJ_Valuation_Month')\n",
    "\n",
    "tdf_row=tdf1.withColumn(\"row_number\",row_number().over(windowSpec))\n",
    "tdf_test=tdf_row.select(\"*\").where(\"row_number='1'\")\n",
    "tdf_test=tdf_test.drop(\"row_number\")\n",
    "\n",
    "tdf3=tdf.union(tdf_test)\n",
    "\n",
    "windowSpec=Window.partitionBy('VPJ_Job_Code').orderBy('VPJ_Valuation_Year','VPJ_Valuation_Month')\n",
    "tdf4 = tdf3.withColumn(\"Month\",row_number().over(windowSpec))\n",
    "\n",
    "tdf6 = tdf4.select([max(\"Month\")])\n",
    "\n",
    "tdf_collect=tdf6.collect()[0][0]\n",
    "\n",
    "tdf5 = tdf4.withColumn(\"POT\", (tdf4[\"Month\"]/tdf_collect)*100)\n",
    "\n",
    "tdf7 = tdf5.withColumn(\"sales\" , tdf5['VPJ_wip_cost'] + tdf5['VPJ_wip_rsv']).withColumn(\"CC\" , (tdf5[\"VPJ_Cum_Cost_AC\"]/(tdf5['VPJ_rev_cost']+ tdf5['VPJ_Contingency_calculated']))*100)\n",
    "\n",
    "tdf9 = tdf7.withColumn(\"logval\" , log('sales'))\n",
    "\n",
    "tdf9.show(5)\n",
    "\n",
    "\n",
    "tdf10 = tdf9.withColumn(\"VPJ_Cost_M\" , col('VPJ_Cum_Cost_AC') - lag(col('VPJ_Cum_Cost_AC'), 1,0).over(windowSpec))\n",
    "\n",
    "tdf11 = tdf10.withColumn(\"SOI\" , tdf10[\"sales\"] - tdf10[\"VPJ_Expected_certified\"])\n",
    "\n",
    "tdf12 = tdf11.withColumn(\"SP\" ,(tdf11[\"sales\"] / tdf11[\"VPJ_Org_contract_value\"])*100)\n",
    "\n",
    "tdf13 = tdf12.where('CC >= 25')\n",
    "\n",
    "tdf14 = tdf12.withColumn(\"CP\" , (tdf13[\"VPJ_Cum_Cost_AC\"] / tdf13[\"VPJ_Org_contract_value\"])*100 ).select('SP','POT' ,'CC','CP')\n",
    "\n",
    "tdf14.repartition(1).write.format('csv').mode('overwrite').save(\"/Internship/Test/Mod2\",header=True)\n",
    "'''\n",
    "op:FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tdf_fin = tdf14.select('SP','POT' ,'CC','CP').where('SP !=0')\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "tdf8 = tdf_fin.drop('SP')\n",
    "assembler = VectorAssembler(inputCols = tdf8.columns, outputCol = 'features')\n",
    "output1=assembler.transform(tdf_fin)\n",
    "op:FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tdf_reg = output1.select(['features' , 'SP'])\n",
    "op:FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr_p = lr_model.transform(tdf_reg)\n",
    "lr_p.show()\n",
    "\n",
    "\n",
    "\n",
    "lr_p.drop('features').repartition(1).write.format('csv').mode('overwrite').save(\"/Internship/Results/Pred1\",header=True)\n",
    "op:\n",
    "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "+--------------------+------------------+------------------+\n",
    "|            features|                SP|        prediction|\n",
    "+--------------------+------------------+------------------+\n",
    "|[5.0,0.2887623310...| 0.268549069935981|0.5114764208405103|\n",
    "|[7.5,1.3776833540...|1.2812456211048107|1.5555060116832682|\n",
    "|[10.0,5.383929778...| 4.501891482677934| 5.041749793097976|\n",
    "|[12.5,11.43869738...| 9.570725719720587|10.536702164476234|\n",
    "|[15.0,57.60810346...| 54.86510603309903|51.980221393472874|\n",
    "|[17.5,64.12666366...| 61.07313367907157|59.688340003615785|\n",
    "|[20.0,82.03090822...| 78.12281968706411| 76.31488306416821|\n",
    "|[22.5,87.26379054...| 83.10633529191715| 83.67011888272945|\n",
    "|[25.0,86.99616418...| 82.85128194046756| 83.35553447432387|\n",
    "|[27.5000000000000...| 90.44873059330502| 84.44167638020932|\n",
    "|[30.0,95.40942917...| 90.86443922137465| 84.77317671721427|\n",
    "|[32.5,96.45718532...|  93.2236513378409|   86.587013050475|\n",
    "|[35.0,97.20802878...|  93.9492132074405| 87.20681427397659|\n",
    "|[37.5,98.34717797...| 95.40723764556579| 86.85248903196636|\n",
    "|[40.0,97.54381553...| 94.62845868241526| 87.39845548363938|\n",
    "|[42.5,98.05394455...| 95.13507431262366| 87.80128350894778|\n",
    "|[45.0,98.68836931...| 95.75145312621972| 88.31610558363934|\n",
    "|[47.5,98.82389843...| 95.88213988358905| 88.54630068427363|\n",
    "|[50.0,98.84618277...| 95.90352223177756| 90.05327266228407|\n",
    "|[52.5,98.85101096...| 95.90953875696535|  90.4121271443733|\n",
    "+--------------------+------------------+------------------+\n",
    "only showing top 20 rows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_e = RegressionEvaluator(predictionCol = \"prediction\", labelCol = \"SP\" , metricName = \"r2\")\n",
    "print(\"R squared on test data = %g\" % lr_e.evaluate(lr_p) )\n",
    "\n",
    "test_result = lr_model.evaluate(tdf_reg)\n",
    "print(\"RMSE on test data  = %g \" % test_result.rootMeanSquaredError )\n",
    "op:FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…\n",
    "R squared on test data = 0.976771\n",
    "RMSE on test data  = 4.41196"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
